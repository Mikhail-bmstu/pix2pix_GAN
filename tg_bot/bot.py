from aiogram import Bot, Dispatcher, types
from aiogram.utils import executor
import logging
from PIL import Image
import numpy as np
from torchvision import transforms as T
from model import *

f2c_model = {
    "discriminator": Discriminator(),
    "generator": Generator()
}

load_model(f2c_model, path_to_disc_weigths, path_to_gen_weigths)

TOKEN = 'TELEGRAM BOT TOKEN (view in submit)'
# log level
logging.basicConfig(level=logging.INFO)

# bot int
bot = Bot(token=TOKEN)
dp = Dispatcher(bot)

@dp.message_handler(commands=['start'])
async def process_start_command(message: types.Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç!\n"
                         "–¢—ã —Å–µ–≥–æ–¥–Ω—è –æ—Ç–ª–∏—á–Ω–æ –≤—ã–≥–ª—è–¥–∏—à—å üòé")
    await message.answer("–ü—Ä–∏—à–ª–∏ –º–Ω–µ —Å–≤–æ–π –ø–æ—Ä—Ç—Ä–µ—Ç, –∏ —è –æ—Ñ–æ—Ä–º–ª—é –µ–≥–æ –≤ —Å—Ç–∏–ª–µ –∫–æ–º–∏–∫—Å–∞ üòú\n"
                        "–ø–æ–¥—Ä–æ–±–Ω–µ–µ: /help")

@dp.message_handler(commands=['help'])
async def process_help_cmd(message: types.Message):
    await message.answer("–î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –º–Ω–µ –ø—Ä–∏–¥–µ—Ç—Å—è –æ–±—Ä–µ–∑–∞—Ç—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –¥–æ –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –ø–æ —Ü–µ–Ω—Ç—Ä—É üî≥, "
                        "—á—Ç–æ–±—ã —è –Ω–µ —É–¥–∞–ª–∏–ª –ª–∏—à–Ω–µ–≥–æ, –º–æ–∂–µ—à—å –æ–±—Ä–µ–∑–∞—Ç—å –µ–µ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ üëâüëà\n"
                         "–Ø —É—á–∏–ª—Å—è —Å–æ–≤—Å–µ–º –Ω–µ–º–Ω–æ–≥–æ, –ø–æ—ç—Ç–æ–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—É–¥–µ—Ç —Ä–∞–∑—Ä–µ—â–µ–Ω–∏–µ–º 128—Ö128 ü•¥\n"
                         "–ö—Å—Ç–∞—Ç–∏, –º–æ–∂–µ—à—å –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —á—Ç–æ-—Ç–æ –∫—Ä–æ–º–µ –ª–∏—Ü–∞, –Ω–æ –∑–∞ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–µ —Ä—É—á–∞—é—Å—å üòÖ")
    

@dp.message_handler(content_types=['photo'])
async def process_photo(message: types.Message):
    await message.photo[-1].download('img/face.jpg')
    await message.reply("–ü—Ä–∏–Ω—è–ª üòâ\n–ü–æ–¥–æ–∂–¥–∏ –Ω–µ–º–Ω–æ–≥–æ)")
    image = Image.open('img/face.jpg')
    image.load()
    width, height = image.size
    pic_size = min(width, height)
    
    left = (width - pic_size) / 2
    top = (height - pic_size) / 2
    right = (width + pic_size) / 2
    bottom = (height + pic_size) / 2

    # Crop the center of the image
    image = image.crop((left, top, right, bottom))
    arr_image = np.array(image) / 255.0

    # Dataset stats
    mean_ds = np.array([0.02437675, -0.17417155, -0.26729974])
    std_ds = np.array([0.47649799, 0.39678715, 0.37886345])

    # Image stats
    mean_img = arr_image.mean(axis=(0, 1))
    std_img = arr_image.std(axis=(0, 1))

    mean = mean_img - mean_ds
    std = std_img / std_ds
    transform_bot = T.Compose([
        T.ToTensor(),
        T.CenterCrop(pic_size),
        T.Resize(size=(128, 128), antialias=False),
        T.Normalize(mean, std)
    ])

    await message.answer("–ó–∞–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –º–æ–¥–µ–ª—å...")
    face = transform_bot(image)
    face = face[None, :, :, :]
    comic = f2c_model["generator"](face)
    comic = comic * mean[0] + std[0]
    image = T.ToPILImage()(torch.squeeze(comic))
    comic_path = 'img/comic.jpg'
    image.save(comic_path)
    with open(comic_path, 'rb') as photo:
        chat_id = message.from_user.id
        await dp.bot.send_photo(chat_id=chat_id, photo=photo)
    
if __name__ == '__main__':
    executor.start_polling(dp, skip_updates=True)

